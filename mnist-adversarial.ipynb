{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib.pyplot import imsave\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "image_pixels = 28\n",
    "kernel = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initialise(shape):\n",
    "    value = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(value)\n",
    "\n",
    "def bias_initialise(shape):\n",
    "    value = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "targets = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn\n",
    "input_layer = tf.reshape(x, [-1, image_pixels, image_pixels, 1])\n",
    "\n",
    "weights1 = weight_initialise([kernel, kernel, 1, 32])\n",
    "bias1 = bias_initialise([32])\n",
    "output1 = tf.nn.relu(tf.nn.conv2d(input_layer, weights1, strides=[1, 1, 1, 1], padding='SAME')+bias1)\n",
    "pool1 = tf.nn.max_pool(output1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "weights2 = weight_initialise([kernel, kernel, 32, 64])\n",
    "bias2 = bias_initialise([64])\n",
    "output2 = tf.nn.relu(tf.nn.conv2d(pool1, weights2, strides=[1, 1, 1, 1], padding='SAME')+bias2)\n",
    "pool2 = tf.nn.max_pool(output2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "weights_fc1 = weight_initialise([7*7*64, 1024])\n",
    "bias_fc1 = bias_initialise([1024])\n",
    "\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7*7*64])\n",
    "\n",
    "output_fc1 = tf.nn.relu(tf.matmul(pool2_flat, weights_fc1) + bias_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout = tf.nn.dropout(output_fc1, keep_prob)\n",
    "\n",
    "weights_fc2 = weight_initialise([1024, 10])\n",
    "bias_fc2 = bias_initialise([10])\n",
    "y_conv = tf.matmul(dropout, weights_fc2) + bias_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "train = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(targets,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "step 200, training accuracy 0.94\n",
      "step 400, training accuracy 0.99\n",
      "step 600, training accuracy 0.98\n",
      "step 800, training accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for i in range(1000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(100)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_x, targets: batch_y, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train.run(feed_dict={x: batch_x, targets: batch_y, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9635\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[0:10000], \n",
    "                                                  targets: mnist.test.labels[0:10000], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "imageshow = mnist.test.images[1].reshape(28,28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 adv accuracy nan\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE04DbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5dfc4ded10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 adv accuracy 0\n",
      "step 20 adv accuracy 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-07d3e86ac166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Calculate loss, derivative and create adversarial image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimage_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimage_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[0;32m--> 542\u001b[0;31m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    543\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    346\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[0;32m--> 542\u001b[0;31m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    543\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.pyc\u001b[0m in \u001b[0;36m_AddGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m   \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m   \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   return (array_ops.reshape(math_ops.reduce_sum(grad, rx), sx),\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[0;32m--> 245\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n\u001b[1;32m    105\u001b[0m       \u001b[0;34m\"Const\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;31m# calls the C / C-API directly, we should be able to remove this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     return {\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0;34m\"shapes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0;34m\"handle_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     }\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \"\"\"\n\u001b[1;32m   1702\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tensor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m       raise ValueError(\"No attr named '\" + name + \"' in \" +\n\u001b[1;32m   1705\u001b[0m                        str(self._node_def))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#adversarial images\n",
    "for i in range(1000):\n",
    "    x_image = mnist.test.images[i]\n",
    "    x_image= np.reshape(x_image, (1, 784))\n",
    "    y_label=mnist.test.labels[i]\n",
    "    \n",
    "    original_image = x_image\n",
    "    \n",
    "    # Calculate loss, derivative and create adversarial image\n",
    "    loss =  tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv)\n",
    "    grad = tf.gradients(loss, x)\n",
    "    image_adv = x+tf.sign(grad)*0.25\n",
    "    image_adv = tf.clip_by_value(image_adv, 0, 1) \n",
    " \n",
    "    x_adv = sess.run(image_adv, {x: x_image, keep_prob: 1.0})\n",
    "        \n",
    "    mnist.test.images[i]= np.reshape(x_adv, (1, 784)) \n",
    "\n",
    "    # adversarial image\n",
    "    if i==1:\n",
    "        imageshow = mnist.test.images[1].reshape(28,28)\n",
    "        plt.imshow(imageshow)\n",
    "        plt.show()\n",
    "        \n",
    "    if i%10 == 0:\n",
    "        print(\"step %d adv accuracy %g\"%(i,accuracy.eval(feed_dict={x: mnist.test.images[0:i], \n",
    "                                                  targets: mnist.test.labels[0:i], keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
