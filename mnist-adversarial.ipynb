{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib.pyplot import imsave\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "image_pixels = 28\n",
    "kernel = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initialise(shape):\n",
    "    value = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(value)\n",
    "\n",
    "def bias_initialise(shape):\n",
    "    value = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "targets = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn\n",
    "input_layer = tf.reshape(x, [-1, image_pixels, image_pixels, 1])\n",
    "\n",
    "params_conv1 = weight_initialise([kernel, kernel, 1, 32])\n",
    "bias_conv1 = bias_initialise([32])\n",
    "output_conv1 = tf.nn.relu(tf.nn.conv2d(input_layer, params_conv1, strides=[1, 1, 1, 1], padding='SAME')+bias_conv1)\n",
    "pool_conv1 = tf.nn.max_pool(output_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "params_conv2 = weight_initialise([kernel, kernel, 32, 64])\n",
    "bias_conv2 = bias_initialise([64])\n",
    "output_conv2 = tf.nn.relu(tf.nn.conv2d(pool_conv1, params_conv2, strides=[1, 1, 1, 1], padding='SAME')+bias_conv2)\n",
    "pool_conv2 = tf.nn.max_pool(output_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "params_fc1 = weight_initialise([7*7*64, 1024])\n",
    "bias_fc1 = bias_initialise([1024])\n",
    "\n",
    "pool_conv2_flat = tf.reshape(pool_conv2, [-1, 7*7*64])\n",
    "\n",
    "output_fc1 = tf.nn.relu(tf.matmul(pool_conv2_flat, params_fc1) + bias_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout = tf.nn.dropout(output_fc1, keep_prob)\n",
    "\n",
    "params_fc2 = weight_initialise([1024, 10])\n",
    "bias_fc2 = bias_initialise([10])\n",
    "y_conv = tf.matmul(dropout, params_fc2) + bias_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "train = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(targets,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.04\n",
      "step 200, training accuracy 0.93\n",
      "step 400, training accuracy 0.96\n",
      "step 600, training accuracy 0.96\n",
      "step 800, training accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for i in range(1000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(100)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_x, targets: batch_y, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train.run(feed_dict={x: batch_x, targets: batch_y, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[0:500], \n",
    "                                                  targets: mnist.test.labels[0:500], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adversarial images\n",
    "for i in range(500):\n",
    "    x_image = mnist.test.images[i]\n",
    "    x_image= np.reshape(x_image, (1, 784))\n",
    "    y_label=mnist.test.labels[i]\n",
    "    \n",
    "    original_image = x_image\n",
    "    probs_per_step = []\n",
    "    \n",
    "    # Calculate loss, derivative and create adversarial image\n",
    "    loss =  tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv)\n",
    "    grad = tf.gradients(loss, x)\n",
    "    image_adv = tf.stop_gradient(x+tf.sign(grad)*0.25)\n",
    "    image_adv = tf.clip_by_value(image_adv, 0, 1) \n",
    "    \n",
    "    dydx = sess.run(grad, {x: x_image, keep_prob: 1.0}) \n",
    "    x_adv = sess.run(image_adv, {x: x_image, keep_prob: 1.0})\n",
    "    \n",
    "    x_image = np.reshape(x_adv, (1, 784))\n",
    "    img_adv_list = original_image\n",
    "    img_adv_list = np.append(img_adv_list, dydx[0], axis=0)\n",
    "    img_adv_list = np.append(img_adv_list, x_image, axis=0)\n",
    "        \n",
    "    prob = y.eval(feed_dict={x: img_adv_list, keep_prob: 1.0})\n",
    "    for j in range(len(prob)):\n",
    "        image= np.reshape(img_adv_list[j], (1, 784))\n",
    "        if (j % 3 == 2): \n",
    "            mnist.test.images[i]=image\n",
    "            \n",
    "print(\"adv accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[0:500], \n",
    "                                                  targets: mnist.test.labels[0:500], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
