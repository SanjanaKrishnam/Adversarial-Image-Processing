{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib.pyplot import imsave\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "image_pixels = 28\n",
    "kernel = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initialise(shape):\n",
    "    value = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(value)\n",
    "\n",
    "def bias_initialise(shape):\n",
    "    value = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "targets = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn\n",
    "input_layer = tf.reshape(x, [-1, image_pixels, image_pixels, 1])\n",
    "\n",
    "params_conv1 = weight_initialise([kernel, kernel, 1, 32])\n",
    "bias_conv1 = bias_initialise([32])\n",
    "output_conv1 = tf.nn.relu(tf.nn.conv2d(input_layer, params_conv1, strides=[1, 1, 1, 1], padding='SAME')+bias_conv1)\n",
    "pool_conv1 = tf.nn.max_pool(output_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "params_conv2 = weight_initialise([kernel, kernel, 32, 64])\n",
    "bias_conv2 = bias_initialise([64])\n",
    "output_conv2 = tf.nn.relu(tf.nn.conv2d(pool_conv1, params_conv2, strides=[1, 1, 1, 1], padding='SAME')+bias_conv2)\n",
    "pool_conv2 = tf.nn.max_pool(output_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "params_fc1 = weight_initialise([7*7*64, 1024])\n",
    "bias_fc1 = bias_initialise([1024])\n",
    "\n",
    "pool_conv2_flat = tf.reshape(pool_conv2, [-1, 7*7*64])\n",
    "\n",
    "output_fc1 = tf.nn.relu(tf.matmul(pool_conv2_flat, params_fc1) + bias_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout = tf.nn.dropout(output_fc1, keep_prob)\n",
    "\n",
    "params_fc2 = weight_initialise([1024, 10])\n",
    "bias_fc2 = bias_initialise([10])\n",
    "y_conv = tf.matmul(dropout, params_fc2) + bias_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "train = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(targets,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "step 200, training accuracy 0.85\n",
      "step 400, training accuracy 0.91\n",
      "step 600, training accuracy 0.95\n",
      "step 800, training accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for i in range(1000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(100)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_x, targets: batch_y, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train.run(feed_dict={x: batch_x, targets: batch_y, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.968\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[0:500], \n",
    "                                                  targets: mnist.test.labels[0:500], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHgiL8QFCEHwiK8ANB/R5UEeYO44sn+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f644668aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original image\n",
    "imageshow = mnist.test.images[1].reshape(28,28)\n",
    "plt.imshow(imageshow)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 adv accuracy nan\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIrwA0ERfiAowg8E9f9SBAlz7a7+zQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63ea63e9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 adv accuracy 0.1\n",
      "step 20 adv accuracy 0.05\n",
      "step 30 adv accuracy 0.0666667\n",
      "step 40 adv accuracy 0.05\n",
      "step 50 adv accuracy 0.04\n",
      "step 60 adv accuracy 0.05\n",
      "step 70 adv accuracy 0.0428571\n",
      "step 80 adv accuracy 0.05\n",
      "step 90 adv accuracy 0.0666667\n",
      "step 100 adv accuracy 0.06\n",
      "step 110 adv accuracy 0.0636364\n",
      "step 120 adv accuracy 0.0583333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3609815d331d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdydx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sharanya/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#adversarial images\n",
    "for i in range(1000):\n",
    "    x_image = mnist.test.images[i]\n",
    "    x_image= np.reshape(x_image, (1, 784))\n",
    "    y_label=mnist.test.labels[i]\n",
    "    \n",
    "    original_image = x_image\n",
    "    probs_per_step = []\n",
    "    \n",
    "    # Calculate loss, derivative and create adversarial image\n",
    "    loss =  tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv)\n",
    "    grad = tf.gradients(loss, x)\n",
    "    image_adv = x+tf.sign(grad)*0.25\n",
    "    image_adv = tf.clip_by_value(image_adv, 0, 1) \n",
    "    \n",
    "    dydx = sess.run(grad, {x: x_image, keep_prob: 1.0}) \n",
    "    x_adv = sess.run(image_adv, {x: x_image, keep_prob: 1.0})\n",
    "    \n",
    "    x_image = np.reshape(x_adv, (1, 784))\n",
    "    img_adv_list = original_image\n",
    "    img_adv_list = np.append(img_adv_list, dydx[0], axis=0)\n",
    "    img_adv_list = np.append(img_adv_list, x_image, axis=0)\n",
    "        \n",
    "    prob = y.eval(feed_dict={x: img_adv_list, keep_prob: 1.0})\n",
    "    for j in range(len(prob)):\n",
    "        image= np.reshape(img_adv_list[j], (1, 784))\n",
    "        if (j % 3 == 2): \n",
    "            mnist.test.images[i]=image\n",
    "    \n",
    "    # adversarial image\n",
    "    if i==1:\n",
    "        imageshow = mnist.test.images[1].reshape(28,28)\n",
    "        plt.imshow(imageshow)\n",
    "        plt.show()\n",
    "        \n",
    "    if i%10 == 0:\n",
    "        print(\"step %d adv accuracy %g\"%(i,accuracy.eval(feed_dict={x: mnist.test.images[0:i], \n",
    "                                                  targets: mnist.test.labels[0:i], keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
